{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89409e2",
   "metadata": {},
   "source": [
    "*Самостоятельно повторить tfidf (документация https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог)\n",
    "\n",
    "Повторить п.2, но используя уже не медиану, а max\n",
    "\n",
    "*Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (взяв список новостей пользователя)\n",
    "\n",
    "подсказка 1: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал\n",
    "подсказка 2: нужен именно idf, как вес.\n",
    "\n",
    "Сформировать на выходе единую таблицу, сравнивающую качество 2/3 разных метода получения эмбедингов пользователей: median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
    "\n",
    "Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124f2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec3e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"articles.csv\")\n",
    "users = pd.read_csv(\"users_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea3b28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(news.head(3), users.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9304a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install razdel pymorphy2 pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd613f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lufta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#предобработка текстов\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import re\n",
    "import numpy as np\n",
    "from razdel import tokenize  # https://github.com/natasha/razdel\n",
    "import pymorphy2\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddf53e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ru = nltk.corpus.stopwords.words('russian')\n",
    "len(stopword_ru)\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a9932ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8065b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Очистка текста\n",
    "    :return: Очищеный текст\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '',\n",
    "                  text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "\n",
    "    # tokens = list(tokenize(text))\n",
    "    # words = [_.text for _ in tokens]\n",
    "    # words = [w for w in words if w not in stopword_ru]\n",
    "\n",
    "    # return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "\n",
    "cache = {}\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "    \"\"\"\n",
    "    Лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "    :return: Список отлемматизированых токенов\n",
    "    \"\"\"\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-':  # [2]\n",
    "            w = w[1:]\n",
    "        if len(w) > 1:  # [3]\n",
    "            if w in cache:  # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else:  # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "\n",
    "    words_lem_without_stopwords = [\n",
    "        i for i in words_lem if not i in stopword_ru\n",
    "    ]  # [6]\n",
    "\n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db03519c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/27000 [00:00<?, ?it/s]<ipython-input-53-5c199c8b6c00>:13: FutureWarning: Possible nested set at position 39\n",
      "  text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '',\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 27000/27000 [00:22<00:00, 1196.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Запускаем очистку текста. Будет долго...\n",
    "news['title'] = news['title'].progress_apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7dd7a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 27000/27000 [02:56<00:00, 153.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Запускаем лемматизацию текста. Будет очень долго...\n",
    "news['title'] = news['title'].progress_apply(lambda x: lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da1c0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сформируем список наших текстов, разбив еще и на пробелы\n",
    "texts = [t for t in news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9cdc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_topic = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbe92e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# Обучаем модель на корпусе\n",
    "lda = LdaModel(common_corpus, num_topics=N_topic, id2word=common_dictionary)#, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24aa5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Сохраняем модель на диск\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9dd70cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем обученную модель с диска\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17d1c68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'свой', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'nnnn', 'провести', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'работа', 'сказать', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'мочь', 'играть', 'ещё', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'это', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0.07795874), (5, 0.49719733), (16, 0.25213745), (18, 0.15494016)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем новый корпус документов, которые раньше не видели\n",
    "other_texts = list(news['title'].iloc[:3])\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19856515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(lda, text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(N_topic):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "853679b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02918648, 0.        , 0.        , 0.15114433,\n",
       "       0.        , 0.        , 0.45645282, 0.        , 0.02196093,\n",
       "       0.0152399 , 0.18423255, 0.        , 0.        , 0.        ,\n",
       "       0.09473963, 0.04152201, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_vector(lda, news['title'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa1d3191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.184315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094741</td>\n",
       "      <td>0.041525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154858</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043702</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>0.123297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029606</td>\n",
       "      <td>0.267266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  topic_0   topic_1  topic_2  topic_3   topic_4   topic_5  topic_6  \\\n",
       "0       6      0.0  0.029189      0.0      0.0  0.150823  0.000000      0.0   \n",
       "1    4896      0.0  0.000000      0.0      0.0  0.000000  0.000000      0.0   \n",
       "2    4897      0.0  0.078055      0.0      0.0  0.000000  0.497201      0.0   \n",
       "3    4898      0.0  0.000000      0.0      0.0  0.000000  0.623337      0.0   \n",
       "4    4899      0.0  0.000000      0.0      0.0  0.000000  0.000000      0.0   \n",
       "\n",
       "    topic_7  topic_8  ...  topic_10  topic_11  topic_12  topic_13  topic_14  \\\n",
       "0  0.456405      0.0  ...  0.015240  0.184315       0.0    0.0000       0.0   \n",
       "1  0.000000      0.0  ...  0.000000  0.000000       0.0    0.0000       0.0   \n",
       "2  0.000000      0.0  ...  0.000000  0.000000       0.0    0.0000       0.0   \n",
       "3  0.075820      0.0  ...  0.000000  0.065677       0.0    0.0422       0.0   \n",
       "4  0.483896      0.0  ...  0.029606  0.267266       0.0    0.0000       0.0   \n",
       "\n",
       "   topic_15  topic_16  topic_17  topic_18  topic_19  \n",
       "0  0.094741  0.041525  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.976242  \n",
       "2  0.000000  0.252121  0.000000  0.154858  0.000000  \n",
       "3  0.000000  0.000000  0.043702  0.018167  0.123297  \n",
       "4  0.000000  0.196917  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(lda, text) for text in news['title'].values])\n",
    "topic_matrix.columns = [f'topic_{i}' for i in range(N_topic)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+[f'topic_{i}' for i in range(N_topic)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f558cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[[f'topic_{i}' for i in range(N_topic)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f68d2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_mean(user_articles_list, doc_dict):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    # print(user_vector)\n",
    "    user_vector = np.mean(user_vector, 0) \n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7a2580e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_median(user_articles_list, doc_dict):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    # print(user_vector)\n",
    "    user_vector = np.median(user_vector, 0)  # можно не среднее\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a5428e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_max(user_articles_list, doc_dict):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    # print(user_vector)\n",
    "    user_vector = np.max(user_vector, 0)  # можно не среднее\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c04c65dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u107120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u102277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u102444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  churn\n",
       "0  u107120      0\n",
       "1  u102277      0\n",
       "2  u102444      0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"users_churn.csv\")\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce4ea8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_user_embedding(func):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import (f1_score, roc_auc_score, precision_score,\n",
    "                             classification_report, precision_recall_curve, confusion_matrix)\n",
    "    \n",
    "    \n",
    "    \n",
    "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: func(x, doc_dict))])\n",
    "    user_embeddings.columns = [f'topic_{i}' for i in range(N_topic)]\n",
    "    user_embeddings['uid'] = users['uid'].values\n",
    "    user_embeddings = user_embeddings[['uid']+[f'topic_{i}' for i in range(20)]]\n",
    "    \n",
    "    X = pd.merge(user_embeddings, target, 'left')\n",
    "\n",
    "    # разделим данные на train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[[f'topic_{i}' for i in range(20)]], \n",
    "                                                        X['churn'], random_state=0)\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    # обучим \n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # наши прогнозы для тестовой выборки\n",
    "    preds = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Рассчитаем метрики\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    "    roc_auc_score = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return round(thresholds[ix], 4), round(fscore[ix], 4), round(precision[ix], 4), round(recall[ix], 4), round(roc_auc_score, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29fdb352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2178, 0.6881, 0.5884, 0.8286, 0.9508)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_user_embedding(func=get_user_embedding_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0eb4dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2271, 0.7304, 0.6364, 0.8571, 0.9659)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_user_embedding(func=get_user_embedding_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "90be437f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3407, 0.7726, 0.7619, 0.7837, 0.9694)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_user_embedding(func=get_user_embedding_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a901945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.array([\n",
    "    score_user_embedding(func=get_user_embedding_mean),\n",
    "    score_user_embedding(func=get_user_embedding_median),\n",
    "    score_user_embedding(func=get_user_embedding_max)\n",
    "]), columns=['Threshold', 'F-Score', 'Precision', 'Recall', 'ROC AUC'])\n",
    "\n",
    "results['func'] = ['mean', 'median', 'max']\n",
    "results = results.set_index('func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7b8e6fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>func</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.9508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.3407</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Threshold  F-Score  Precision  Recall  ROC AUC\n",
       "func                                                  \n",
       "mean       0.2178   0.6881     0.5884  0.8286   0.9508\n",
       "median     0.2271   0.7304     0.6364  0.8571   0.9659\n",
       "max        0.3407   0.7726     0.7619  0.7837   0.9694"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1c734",
   "metadata": {},
   "source": [
    "MAX показывает лучшие метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403a2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
